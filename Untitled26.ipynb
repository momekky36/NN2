{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8c79e8-20b9-49d6-b0e2-6f4ede868ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Forward Pass: h1=0.3605343933972968, h2=0.5665993699780817, o1=0.6346615718186287, o2=0.7975694207596233\n",
      "Updated Weights: w1=0.1479835261295925, w2=0.19596705225918504, w3=0.24821476538348208, w4=0.29642953076696416, w5=0.34244025183944204, w6=0.3595417312713065, w7=0.5126227093303909, w8=0.5698372729065398\n",
      "Updated Biases: b1=0.30967052259185013, b2=0.5642953076696414\n",
      "\n",
      "Epoch 2\n",
      "Forward Pass: h1=0.3244980571297733, h2=0.5415519610800321, o1=0.5479886728695205, o2=0.7775865365074529\n",
      "Updated Weights: w1=0.1465454741030903, w2=0.19309094820618058, w3=0.24706903282484763, w4=0.29413806564969525, w5=0.2915814370634614, w6=0.2746639014200062, w7=0.5262483198573319, w8=0.5925769347924865\n",
      "Updated Biases: b1=0.2809094820618057, b2=0.5413806564969522\n",
      "\n",
      "Epoch 3\n",
      "Forward Pass: h1=0.298202822387878, h2=0.5249496339612939, o1=0.47153672383855405, o2=0.7655064675943369\n",
      "Updated Weights: w1=0.14574063062122694, w2=0.19148126124245388, w3=0.24662924241546025, w4=0.2932584848309205, w5=0.24850205958878524, w6=0.19882792087654724, w7=0.5401058480009635, w8=0.6169714199564991\n",
      "Updated Biases: b1=0.2648126124245385, b2=0.5325848483092048\n",
      "\n",
      "Epoch 4\n",
      "Forward Pass: h1=0.28328285543352294, h2=0.5184679250537793, o1=0.41223007912982124, o2=0.7638808074656812\n",
      "Updated Weights: w1=0.14542929594171383, w2=0.19085859188342766, w3=0.2467493958640998, w4=0.2934987917281996, w5=0.21179261198169236, w6=0.13164181777972142, w7=0.5534450007505434, w8=0.6413849088613122\n",
      "Updated Biases: b1=0.2585859188342764, b2=0.534987917281996\n",
      "\n",
      "Epoch 5\n",
      "Forward Pass: h1=0.2774739637799678, h2=0.5202447463199712, o1=0.3677673770315284, o2=0.770773928456452\n",
      "Updated Weights: w1=0.14543409056346973, w2=0.19086818112693946, w3=0.24723426766919593, w4=0.29446853533839185, w5=0.17966791428569245, w6=0.07141020189840534, w7=0.5657905829306381, w8=0.6645320329444527\n",
      "Updated Biases: b1=0.25868181126939443, b2=0.5446853533839183\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "   \n",
    "def tanh(x):\n",
    "    return (math.exp(x) - math.exp(-x)) / (math.exp(x) + math.exp(-x))\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - tanh(x) ** 2\n",
    "\n",
    "i1, i2 = 0.05, 0.10\n",
    "\n",
    "w1, w2, w3, w4 = 0.15, 0.20, 0.25, 0.30\n",
    "w5, w6, w7, w8 = 0.40, 0.45, 0.50, 0.55\n",
    "\n",
    "b1, b2 = 0.35, 0.60\n",
    "\n",
    "t1, t2 = 0.1, 0.99\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "\n",
    "\n",
    "def back_propagation():\n",
    "    global w1, w2, w3, w4, w5, w6, w7, w8, b1, b2\n",
    "\n",
    "    error_o1 = (t1 - o1) * tanh_derivative(net_o1)\n",
    "    error_o2 = (t2 - o2) * tanh_derivative(net_o2)\n",
    "\n",
    "    delta_w5 = learning_rate * error_o1 * h1\n",
    "    delta_w6 = learning_rate * error_o1 * h2\n",
    "    delta_w7 = learning_rate * error_o2 * h1\n",
    "    delta_w8 = learning_rate * error_o2 * h2\n",
    "\n",
    "    error_h1 = (error_o1 * w5 + error_o2 * w7) * tanh_derivative(net_h1)\n",
    "    error_h2 = (error_o1 * w6 + error_o2 * w8) * tanh_derivative(net_h2)\n",
    "\n",
    "    delta_w1 = learning_rate * error_h1 * i1\n",
    "    delta_w2 = learning_rate * error_h1 * i2\n",
    "    delta_w3 = learning_rate * error_h2 * i1\n",
    "    delta_w4 = learning_rate * error_h2 * i2\n",
    "\n",
    "    w1 += delta_w1\n",
    "    w2 += delta_w2\n",
    "    w3 += delta_w3\n",
    "    w4 += delta_w4\n",
    "    w5 += delta_w5\n",
    "    w6 += delta_w6\n",
    "    w7 += delta_w7\n",
    "    w8 += delta_w8\n",
    "\n",
    "    b1 += learning_rate * error_h1\n",
    "    b2 += learning_rate * error_h2\n",
    "\n",
    "    print(f\"Updated Weights: w1={w1}, w2={w2}, w3={w3}, w4={w4}, w5={w5}, w6={w6}, w7={w7}, w8={w8}\")\n",
    "    print(f\"Updated Biases: b1={b1}, b2={b2}\")\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    print(f\"\\nEpoch {epoch}\")\n",
    "    forward_propagation()\n",
    "    back_propagation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3391555-7bdb-4409-b855-cd4ad35d14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation():\n",
    "    global h1, h2, o1, o2, net_h1, net_h2, net_o1, net_o2\n",
    "\n",
    "    net_h1 = (w1 * i1) + (w2 * i2) + b1\n",
    "    h1 = tanh(net_h1)\n",
    "\n",
    "    net_h2 = (w3 * i1) + (w4 * i2) + b2\n",
    "    h2 = tanh(net_h2)\n",
    "\n",
    "    net_o1 = (w5 * h1) + (w6 * h2) + b1\n",
    "    o1 = tanh(net_o1)\n",
    "\n",
    "    net_o2 = (w7 * h1) + (w8 * h2) + b2\n",
    "    o2 = tanh(net_o2)\n",
    "\n",
    "    print(f\"Forward Pass: h1={h1}, h2={h2}, o1={o1}, o2={o2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2ad34a-d6ce-4791-911e-cd80300f34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation():\n",
    "    global w1, w2, w3, w4, w5, w6, w7, w8, b1, b2\n",
    "\n",
    "    error_o1 = (t1 - o1) * tanh_derivative(net_o1)\n",
    "    error_o2 = (t2 - o2) * tanh_derivative(net_o2)\n",
    "\n",
    "    delta_w5 = learning_rate * error_o1 * h1\n",
    "    delta_w6 = learning_rate * error_o1 * h2\n",
    "    delta_w7 = learning_rate * error_o2 * h1\n",
    "    delta_w8 = learning_rate * error_o2 * h2\n",
    "\n",
    "    error_h1 = (error_o1 * w5 + error_o2 * w7) * tanh_derivative(net_h1)\n",
    "    error_h2 = (error_o1 * w6 + error_o2 * w8) * tanh_derivative(net_h2)\n",
    "\n",
    "    delta_w1 = learning_rate * error_h1 * i1\n",
    "    delta_w2 = learning_rate * error_h1 * i2\n",
    "    delta_w3 = learning_rate * error_h2 * i1\n",
    "    delta_w4 = learning_rate * error_h2 * i2\n",
    "\n",
    "    w1 += delta_w1\n",
    "    w2 += delta_w2\n",
    "    w3 += delta_w3\n",
    "    w4 += delta_w4\n",
    "    w5 += delta_w5\n",
    "    w6 += delta_w6\n",
    "    w7 += delta_w7\n",
    "    w8 += delta_w8\n",
    "\n",
    "    b1 += learning_rate * error_h1\n",
    "    b2 += learning_rate * error_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a21f450-626b-44d6-aae7-b883a20df9ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (458949759.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"Updated Biases: b1={b1}, b2={b2}\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "   print(f\"Updated Weights: w1={w1}, w2={w2}, w3={w3}, w4={w4}, w5={w5}, w6={w6}, w7={w7}, w8={w8}\")\n",
    "    print(f\"Updated Biases: b1={b1}, b2={b2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c036f7-a521-466d-b81f-bfac1fd81028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
